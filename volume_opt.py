import os
import glob
import math
import gc
import joblib
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import MiniBatchKMeans  # KMeansë³´ë‹¤ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ë¹ ë¦„
from sklearn.manifold import TSNE
from collections import Counter
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ì´ ê·¸ë˜í”„ ì €ì¥

# --- 1. ë°ì´í„° ë¡œë” (ì‹ ê·œ í•¨ìˆ˜) ---
# ìš”ì²­í•˜ì‹  ë””ë ‰í† ë¦¬ êµ¬ì¡°ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
def load_data_from_dumps(base_dir, ticker, interval, start_date_str, end_date_str, 
                         features_to_use):
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì—ì„œ ë‚ ì§œ ë²”ìœ„ ë‚´ì˜ ëª¨ë“  CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë³‘í•©í•©ë‹ˆë‹¤.
    """
    print(f"ë°ì´í„° ë¡œë“œ ì¤‘... ({start_date_str} ~ {end_date_str})")
    start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
    end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
    
    all_dfs = []
    current_date = start_date
    
    while current_date <= end_date:
        date_str = current_date.strftime('%Y-%m-%d')
        # ./dumps/BTC/3m/2025-06-17/*.csv
        search_path = os.path.join(base_dir, ticker, interval, date_str, '*.csv')
        csv_files = sorted(glob.glob(search_path)) # 00.csv, 01.csv... ìˆœì„œ ë³´ì¥
        
        for f in csv_files:
            try:
                # ì²« ë²ˆì§¸ ì—´ì„ ì¸ë±ìŠ¤(ì‹œê°„)ë¡œ ì‚¬ìš©
                df = pd.read_csv(f, index_col=0, parse_dates=True)
                all_dfs.append(df)
            except Exception as e:
                print(f"ê²½ê³ : {f} íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        
        current_date += timedelta(days=1)
        
    if not all_dfs:
        print("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
        
    # ëª¨ë“  DataFrame ë³‘í•©
    full_df = pd.concat(all_dfs)
    full_df = full_df.sort_index() # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
    full_df = full_df[~full_df.index.duplicated(keep='first')] # ì¤‘ë³µ ì¸ë±ìŠ¤ ì œê±°
    
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    try:
        selected_df = full_df[features_to_use]
        selected_df = selected_df.dropna() # ì´ë™í‰ê·  ë“±ìœ¼ë¡œ ì¸í•œ NaN ê°’ ì œê±°
        print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ. ì´ {len(selected_df)}ê°œì˜ í‹±(row) í™•ë³´.")
        return selected_df
    except KeyError as e:
        print(f"ì˜¤ë¥˜: ìš”ì²­ëœ í”¼ì²˜(ì»¬ëŸ¼) {e}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {full_df.columns.tolist()}")
        return pd.DataFrame()

# --- 2. PyTorch ë°ì´í„°ì…‹ (ì´ë™í‰ê·  ë° íŒŒìƒ ì§€í‘œìš©) ---
# ë‹¤ì¤‘ í”¼ì²˜(ma5, check_5_10, diff_s2e, diff_h2l, PON)ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
class PricePatternDataset(Dataset):
    """
    ë‹¤ì¤‘ í”¼ì²˜ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ (seq_len, num_features) í…ì„œë¡œ ë°˜í™˜í•˜ëŠ” ë°ì´í„°ì…‹
    ì„ì˜ì˜ ìœ„ì¹˜ì—ì„œ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ì—¬ ì—°ì†ì  ë°ì´í„° ì¸ì‹ ë¬¸ì œë¥¼ ë°©ì§€
    
    Args:
        random_sampling: Trueë©´ ëœë¤ ìƒ˜í”Œë§ (Trainingìš©), Falseë©´ ê³ ì • ìƒ˜í”Œë§ (Validationìš©)
    """
    def __init__(self, data, seq_len, random_sampling=True):
        # dataëŠ” (N, num_features) í˜•íƒœì˜ ìŠ¤ì¼€ì¼ë§ëœ NumPy ë°°ì—´
        self.data = data
        self.seq_len = seq_len
        self.num_features = data.shape[1]
        self.random_sampling = random_sampling
        
        if len(data) < seq_len:
            raise ValueError(f"ë°ì´í„° ê¸¸ì´({len(data)})ê°€ ì‹œí€€ìŠ¤ ê¸¸ì´({seq_len})ë³´ë‹¤ ì§§ìŠµë‹ˆë‹¤.")
        
        # ëœë¤ ìƒ˜í”Œë§ì„ ìœ„í•œ ìœ íš¨í•œ ì¸ë±ìŠ¤ ë²”ìœ„
        # seq_len ì´ìƒì˜ ì¸ë±ìŠ¤ì—ì„œë§Œ ì„ íƒí•˜ì—¬ ì´ì „ 50ê°œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ í•¨
        self.valid_start_idx = seq_len - 1  # ìµœì†Œ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ)
        self.valid_end_idx = len(data) - 1  # ìµœëŒ€ ì¸ë±ìŠ¤
        
        # ê³ ì • ìƒ˜í”Œë§ìš© ì¸ë±ìŠ¤ ìƒì„± (Validationì—ì„œ ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´)
        if not random_sampling:
            self.fixed_indices = np.arange(self.valid_start_idx, self.valid_end_idx + 1)

    def __len__(self):
        # ì¶©ë¶„í•œ ìƒ˜í”Œë§ì„ ìœ„í•´ ì „ì²´ ë°ì´í„° ê¸¸ì´ ë°˜í™˜
        if self.random_sampling:
            # Training: ëœë¤ ìƒ˜í”Œë§ì´ë¯€ë¡œ ë°˜ë³µ íšŸìˆ˜ì— ì˜í–¥ì„ ì¤Œ
            return len(self.data) - self.seq_len + 1
        else:
            # Validation: ê³ ì • ìƒ˜í”Œ ìˆ˜ ë°˜í™˜
            return len(self.fixed_indices)

    def __getitem__(self, idx):
        if self.random_sampling:
            # Training: ì„ì˜ì˜ ìœ„ì¹˜ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ (ì—°ì†ì  ë°ì´í„° ì¸ì‹ ë¬¸ì œ ë°©ì§€)
            random_idx = np.random.randint(self.valid_start_idx, self.valid_end_idx + 1)
        else:
            # Validation: ê³ ì • ìƒ˜í”Œë§ (ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´)
            random_idx = self.fixed_indices[idx % len(self.fixed_indices)]
        
        # ì„ íƒí•œ ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•˜ì—¬ ì´ì „ seq_lenê°œ ë°ì´í„° ì¶”ì¶œ
        # [random_idx - seq_len + 1 : random_idx + 1] í˜•íƒœë¡œ ì´ì „ 50ê°œë¥¼ ê°€ì ¸ì˜´
        start_idx = random_idx - self.seq_len + 1
        end_idx = random_idx + 1
        sample = self.data[start_idx : end_idx]
        
        return torch.tensor(sample, dtype=torch.float32)

# --- 3. íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ (ì‹ ê·œ ì •ì˜) ---
# ì˜ˆì‹œ ì½”ë“œì— ì—†ì—ˆë˜ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

class PositionalEncoding(nn.Module):
    """ Transformerë¥¼ ìœ„í•œ ìœ„ì¹˜ ì¸ì½”ë”© """
    def __init__(self, d_model, max_len=5000, dropout=0.1):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0) # [1, max_len, d_model] (batch_first=True ìš©)
        self.register_buffer('pe', pe)

    def forward(self, x):
        # x shape: [batch, seq_len, d_model]
        x = x + self.pe[:, :x.size(1), :]
        return self.dropout(x)

class TransformerAutoencoder(nn.Module):
    """
    íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”-ë””ì½”ë” ê¸°ë°˜ ì˜¤í† ì¸ì½”ë” (íŒ¨í„´ ì••ì¶•ê¸°)
    [batch, seq_len, input_dim] -> [batch, latent_dim] -> [batch, seq_len, input_dim]
    ê°œì„ ì‚¬í•­:
    - Latent Vector L2 ì •ê·œí™” ì¶”ê°€
    - Dropout ì¶”ê°€ë¡œ ê³¼ì í•© ë°©ì§€
    """
    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, latent_dim, max_seq_len, dropout=0.1):
        super(TransformerAutoencoder, self).__init__()
        self.max_seq_len = max_seq_len
        self.d_model = d_model
        self.num_encoder_layers = num_encoder_layers
        self.num_decoder_layers = num_decoder_layers

        # 1. Input Embedding (input_dim -> d_model)
        self.input_embed = nn.Linear(input_dim, d_model)
        self.pos_encoder = PositionalEncoding(d_model, max_seq_len, dropout=dropout)

        # 2. Encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model*4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)

        # 3. Bottleneck (d_model * seq_len -> latent_dim)
        # ì ì§„ì  ì••ì¶•ìœ¼ë¡œ ì •ë³´ ì†ì‹¤ ìµœì†Œí™” (ë” ë§ì€ ë ˆì´ì–´ ì¶”ê°€)
        intermediate_dim = d_model * max_seq_len // 2
        self.to_latent = nn.Sequential(
            nn.Linear(d_model * max_seq_len, intermediate_dim),
            nn.LayerNorm(intermediate_dim),
            nn.GELU(),  # ReLU -> GELU (ë” ë¶€ë“œëŸ¬ìš´ í™œì„±í™”)
            nn.Dropout(dropout),
            nn.Linear(intermediate_dim, intermediate_dim // 2),
            nn.LayerNorm(intermediate_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(intermediate_dim // 2, latent_dim),
            nn.LayerNorm(latent_dim)  # ìµœì¢… ì •ê·œí™” ì¶”ê°€
        )

        # 4. Decoder Input (latent_dim -> d_model * seq_len)
        # ì ì§„ì  í™•ì¥ìœ¼ë¡œ ë³µì› í’ˆì§ˆ í–¥ìƒ (ëŒ€ì¹­ êµ¬ì¡°)
        self.from_latent = nn.Sequential(
            nn.Linear(latent_dim, intermediate_dim // 2),
            nn.LayerNorm(intermediate_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(intermediate_dim // 2, intermediate_dim),
            nn.LayerNorm(intermediate_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(intermediate_dim, d_model * max_seq_len),
            nn.LayerNorm(d_model * max_seq_len)  # ìµœì¢… ì •ê·œí™” ì¶”ê°€
        )

        # 5. Decoder (TransformerEncoder ì¸µì„ ë””ì½”ë”ë¡œ í™œìš©)
        decoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model*4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer_decoder = nn.TransformerEncoder(decoder_layer, num_layers=num_decoder_layers)

        # 6. Output Layer (d_model -> input_dim)
        self.output_layer = nn.Linear(d_model, input_dim)

    def encode(self, src):
        # src: [batch, seq_len, input_dim]
        src_embed = self.input_embed(src) * math.sqrt(self.d_model)
        src_embed = self.pos_encoder(src_embed) # [batch, seq_len, d_model]

        enc_output = self.transformer_encoder(src_embed) # [batch, seq_len, d_model]

        # Flatten and project to latent
        enc_flat = enc_output.view(enc_output.size(0), -1) # [batch, seq_len * d_model]
        latent = self.to_latent(enc_flat) # [batch, latent_dim]

        # L2 ì •ê·œí™” ì œê±° - ëª¨ë¸ í‘œí˜„ë ¥ í–¥ìƒì„ ìœ„í•´ ì œì•½ í•´ì œ
        # latent = F.normalize(latent, p=2, dim=1)

        return latent

    def decode(self, latent):
        # latent: [batch, latent_dim]
        dec_input_flat = self.from_latent(latent) # [batch, seq_len * d_model]
        dec_input = dec_input_flat.view(latent.size(0), self.max_seq_len, self.d_model)

        dec_input = self.pos_encoder(dec_input) # Add position

        dec_output = self.transformer_decoder(dec_input) # [batch, seq_len, d_model]

        output = self.output_layer(dec_output) # [batch, seq_len, input_dim]
        return output

    def forward(self, src):
        latent = self.encode(src)
        reconstructed = self.decode(latent)
        # ì¬êµ¬ì¶•ëœ ê°’ê³¼ ì ì¬ ë²¡í„°(íŒ¨í„´) ë™ì‹œ ë°˜í™˜
        return reconstructed, latent

# --- 4. ì¡°ê¸° ì¢…ë£Œ (Early Stopping) (ì‹ ê·œ í´ë˜ìŠ¤) ---
# [Req 6, 8] ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ì¡°ê¸° ì¢…ë£Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
class EarlyStopping:
    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pth'):
        """
        Args:
            patience (int): Validation lossê°€ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ê¸°ë‹¤ë¦´ epoch ìˆ˜
            verbose (bool): ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
            delta (float): ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ ë³€í™”ëŸ‰
            path (str): ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ
        """
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.inf
        self.delta = delta
        self.path = path

    def __call__(self, val_loss, model):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                print(f'  [EarlyStopping] Counter: {self.counter} / {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        # [Req 8] ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(os.path.dirname(self.path), exist_ok=True)

        if self.verbose:
            print(f'  [EarlyStopping] Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). \nSaving model to {self.path}')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

# --- 5. Contrastive Loss í•¨ìˆ˜ (ìˆ˜ì •ë¨) ---
def contrastive_loss(latent_vectors, temperature=0.5):
    """
    ê°„ë‹¨í•œ ë¶„ì‚° ìµœëŒ€í™” Loss (ì ì¬ ë²¡í„°ë“¤ì´ ì„œë¡œ ë©€ì–´ì§€ë„ë¡)

    Args:
        latent_vectors: [batch_size, latent_dim] - L2 ì •ê·œí™”ëœ ì ì¬ ë²¡í„°
        temperature: ì‚¬ìš© ì•ˆ í•¨ (í˜¸í™˜ì„± ìœ ì§€)

    Returns:
        contrastive loss value
    """
    batch_size = latent_vectors.shape[0]

    if batch_size < 2:
        return torch.tensor(0.0, device=latent_vectors.device)

    # ë°©ë²• 1: ë²¡í„° ê°„ í‰ê·  ê±°ë¦¬ë¥¼ ìµœëŒ€í™” (= ìœ ì‚¬ë„ë¥¼ ìµœì†Œí™”)
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (L2 ì •ê·œí™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë‚´ì ë§Œ í•˜ë©´ ë¨)
    similarity_matrix = torch.matmul(latent_vectors, latent_vectors.T)

    # ëŒ€ê°ì„  ì œì™¸ (ìê¸° ìì‹ ê³¼ì˜ ìœ ì‚¬ë„ ì œì™¸)
    mask = torch.eye(batch_size, dtype=torch.bool, device=latent_vectors.device)
    off_diagonal = similarity_matrix.masked_select(~mask)

    # Loss: í‰ê·  ìœ ì‚¬ë„ë¥¼ ë‚®ì¶”ê¸° (= ë²¡í„°ë“¤ì´ ì„œë¡œ ë©€ì–´ì§)
    # ìœ ì‚¬ë„ê°€ ë†’ìœ¼ë©´ lossê°€ ë†’ê³ , ìœ ì‚¬ë„ê°€ ë‚®ìœ¼ë©´ lossê°€ ë‚®ìŒ
    loss = off_diagonal.mean()

    return loss

# --- 6. ëª¨ë¸ í•™ìŠµ (ì‹ ê·œ í•¨ìˆ˜) ---
# [Req 6, 7] ì¡°ê¸° ì¢…ë£Œë¥¼ í¬í•¨í•œ í•™ìŠµ ë£¨í”„ + Contrastive Loss
def train_autoencoder(model, train_loader, val_loader, model_path, epochs, lr, patience, device,
                      contrastive_weight=0.1, warmup_epochs=5):
    """
    íŠ¸ëœìŠ¤í¬ë¨¸ ì˜¤í† ì¸ì½”ë” í•™ìŠµ í•¨ìˆ˜

    ê°œì„ ì‚¬í•­:
    - Reconstruction Loss + Perceptual Loss + Contrastive Loss ê²°í•©
    - Learning Rate Warmup + Cosine Annealing
    - ìƒì„¸í•œ í•™ìŠµ ì§„í–‰ ì‹œê°í™”
    - Gradient Accumulation ì§€ì›

    Args:
        contrastive_weight: Contrastive Lossì˜ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ 0.1)
        warmup_epochs: Warmup epoch ìˆ˜
    """
    model.to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.005)  # 0.01 -> 0.005 (ê·œì œ ì™„í™”)

    # MSE Loss (í”½ì…€ ë ˆë²¨ ì¬êµ¬ì¶•)
    mse_criterion = nn.MSELoss()

    # L1 Loss (ë””í…Œì¼ ë³´ì¡´)
    l1_criterion = nn.L1Loss()

    # ê²°í•©ëœ Reconstruction Loss
    def reconstruction_criterion(recon, target):
        # MSE + L1 ê²°í•© (ë””í…Œì¼ ë³´ì¡´ ê°•í™”)
        mse_loss = mse_criterion(recon, target)
        l1_loss = l1_criterion(recon, target)
        return 0.5 * mse_loss + 0.5 * l1_loss

    # Learning Rate Scheduler (Warmup + Cosine Annealing)
    def lr_lambda(current_epoch):
        if current_epoch < warmup_epochs:
            # Warmup: ì„ í˜• ì¦ê°€
            return (current_epoch + 1) / warmup_epochs
        else:
            # Cosine Annealing
            progress = (current_epoch - warmup_epochs) / (epochs - warmup_epochs)
            return 0.5 * (1 + math.cos(math.pi * progress))

    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

    # [Req 6, 8] ì¡°ê¸° ì¢…ë£Œ í•¸ë“¤ëŸ¬ (ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ model_pathì— ì €ì¥)
    early_stopper = EarlyStopping(patience=patience, verbose=True, path=model_path)

    print("\n" + "="*70)
    print("                  ğŸš€  ì˜¤í† ì¸ì½”ë” í•™ìŠµ ì‹œì‘  ğŸš€")
    print("="*70)
    print(f"  Loss: MSE + L1 (0.5:0.5) + Contrastive (weight={contrastive_weight})")
    print(f"  Learning Rate: {lr} (Warmup: {warmup_epochs} epochs)")
    print(f"  Optimizer: AdamW (weight_decay=0.005)")
    print(f"  Model Capacity: d_model={model.d_model}, enc_layers={model.num_encoder_layers}, dec_layers={model.num_decoder_layers}")
    print("="*70)

    best_val_loss = float('inf')

    for epoch in range(1, epochs + 1):
        # --- Training ---
        model.train()
        train_recon_loss = 0.0
        train_contrast_loss = 0.0
        train_total_loss = 0.0

        for data in train_loader:
            data = data.to(device) # (batch, seq_len, num_features)

            optimizer.zero_grad()
            reconstructed, latent = model(data)

            # 1. Reconstruction Loss
            recon_loss = reconstruction_criterion(reconstructed, data)

            # 2. Contrastive Loss
            contrast_loss = contrastive_loss(latent, temperature=0.5)

            # 3. Total Loss
            total_loss = recon_loss + contrastive_weight * contrast_loss

            total_loss.backward()

            # Gradient Clipping (í­ë°œ ë°©ì§€) - ëª¨ë¸ ìš©ëŸ‰ ì¦ê°€ë¡œ max_norm ì¡°ì •
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)

            optimizer.step()

            train_recon_loss += recon_loss.item() * data.size(0)
            train_contrast_loss += contrast_loss.item() * data.size(0)
            train_total_loss += total_loss.item() * data.size(0)

        # --- Validation ---
        model.eval()
        val_recon_loss = 0.0
        val_contrast_loss = 0.0
        val_total_loss = 0.0

        with torch.no_grad():
            for data in val_loader:
                data = data.to(device)
                reconstructed, latent = model(data)

                recon_loss = reconstruction_criterion(reconstructed, data)
                contrast_loss = contrastive_loss(latent, temperature=0.5)
                total_loss = recon_loss + contrastive_weight * contrast_loss

                val_recon_loss += recon_loss.item() * data.size(0)
                val_contrast_loss += contrast_loss.item() * data.size(0)
                val_total_loss += total_loss.item() * data.size(0)

        # í‰ê·  ê³„ì‚°
        train_recon_loss /= len(train_loader.dataset)
        train_contrast_loss /= len(train_loader.dataset)
        train_total_loss /= len(train_loader.dataset)

        val_recon_loss /= len(val_loader.dataset)
        val_contrast_loss /= len(val_loader.dataset)
        val_total_loss /= len(val_loader.dataset)

        current_lr = scheduler.get_last_lr()[0]

        # ì§„í–‰ ìƒí™© ì¶œë ¥ (ê°œì„ ëœ í¬ë§·)
        print(f'Epoch {epoch:04d}/{epochs} | LR: {current_lr:.2e} | '
              f'Train: {train_total_loss:.6f} (R:{train_recon_loss:.6f} C:{train_contrast_loss:.6f}) | '
              f'Val: {val_total_loss:.6f} (R:{val_recon_loss:.6f} C:{val_contrast_loss:.6f})',
              end='')

        # Best ëª¨ë¸ í‘œì‹œ
        if val_total_loss < best_val_loss:
            best_val_loss = val_total_loss
            print(' âœ“ BEST', end='')

        print()  # ì¤„ë°”ê¿ˆ

        # Learning Rate ì¡°ì •
        scheduler.step()

        # --- Early Stopping Check ---
        early_stopper(val_total_loss, model)
        if early_stopper.early_stop:
            print("\n" + "="*70)
            print("                       â›” ì¡°ê¸° ì¢…ë£Œ â›”")
            print(f"  ìµœì  Epoch: {epoch - early_stopper.patience}")
            print(f"  ìµœì € Val Loss: {early_stopper.val_loss_min:.6f}")
            print("="*70)
            break

    # [Req 8] í•™ìŠµ ì™„ë£Œ í›„, ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ë¡œë“œ
    print(f"\ní•™ìŠµ ì¢…ë£Œ. '{model_path}'ì—ì„œ ìµœì  ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
    try:
        model.load_state_dict(torch.load(model_path, map_location=device))
    except Exception as e:
        print(f"ì˜¤ë¥˜: ìµœì  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}. ë§ˆì§€ë§‰ epoch ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")

    return model

# --- 7. ì¬êµ¬ì¶• í’ˆì§ˆ ê²€ì¦ í•¨ìˆ˜ ---
def visualize_reconstruction_quality(model, dataloader, device, save_path, num_samples=5):
    """
    ëª¨ë¸ì˜ ì¬êµ¬ì¶• í’ˆì§ˆì„ ì‹œê°í™”í•˜ì—¬ ì €ì¥

    Args:
        model: í•™ìŠµëœ ì˜¤í† ì¸ì½”ë”
        dataloader: ê²€ì¦ìš© ë°ì´í„°ë¡œë”
        device: ì¥ì¹˜
        save_path: ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
        num_samples: ì‹œê°í™”í•  ìƒ˜í”Œ ìˆ˜
    """
    model.to(device)
    model.eval()

    # ìƒ˜í”Œ ì¶”ì¶œ
    samples = []
    with torch.no_grad():
        for data in dataloader:
            data = data.to(device)
            reconstructed, _ = model(data)

            # CPUë¡œ ì´ë™
            original = data.cpu().numpy()
            recon = reconstructed.cpu().numpy()

            for i in range(min(num_samples, len(original))):
                samples.append((original[i], recon[i]))

            if len(samples) >= num_samples:
                break

    if not samples:
        print("ì¬êµ¬ì¶• í’ˆì§ˆ ì‹œê°í™”: ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì‹œê°í™”
    fig, axes = plt.subplots(num_samples, 2, figsize=(14, 3 * num_samples))

    for idx, (original, recon) in enumerate(samples[:num_samples]):
        # ì›ë³¸
        ax_orig = axes[idx, 0] if num_samples > 1 else axes[0]
        ax_orig.imshow(original.T, aspect='auto', cmap='viridis', interpolation='nearest')
        ax_orig.set_title(f'Original Sample {idx+1}')
        ax_orig.set_xlabel('Time Steps')
        ax_orig.set_ylabel('Features')

        # ì¬êµ¬ì¶•
        ax_recon = axes[idx, 1] if num_samples > 1 else axes[1]
        ax_recon.imshow(recon.T, aspect='auto', cmap='viridis', interpolation='nearest')
        ax_recon.set_title(f'Reconstructed Sample {idx+1}')
        ax_recon.set_xlabel('Time Steps')
        ax_recon.set_ylabel('Features')

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close(fig)
    print(f"âœ“ ì¬êµ¬ì¶• í’ˆì§ˆ ì‹œê°í™” ì €ì¥: {save_path}")

# --- 8. t-SNE ì‹œê°í™” í•¨ìˆ˜ ---
def visualize_latent_space_tsne(latent_vectors, labels, save_path, title="Latent Space (t-SNE)"):
    """
    ì ì¬ ë²¡í„°ë¥¼ t-SNEë¡œ 2D ì¶•ì†Œí•˜ì—¬ ì‹œê°í™”

    Args:
        latent_vectors: numpy array of shape (n_samples, latent_dim)
        labels: numpy array of cluster labels
        save_path: ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
        title: ê·¸ë˜í”„ ì œëª©
    """
    print("\nt-SNEë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì¬ ê³µê°„ ì‹œê°í™” ì¤‘...")

    # t-SNE ì ìš© (ìƒ˜í”Œì´ ë„ˆë¬´ ë§ìœ¼ë©´ ì¼ë¶€ë§Œ ì‚¬ìš©)
    max_samples = 10000
    if len(latent_vectors) > max_samples:
        print(f"  ìƒ˜í”Œ ìˆ˜ê°€ ë§ì•„ {max_samples}ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        indices = np.random.choice(len(latent_vectors), max_samples, replace=False)
        latent_subset = latent_vectors[indices]
        labels_subset = labels[indices]
    else:
        latent_subset = latent_vectors
        labels_subset = labels

    tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)
    latent_2d = tsne.fit_transform(latent_subset)

    # ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(12, 10))

    # ìƒìœ„ 30ê°œ ì¹´í…Œê³ ë¦¬ë§Œ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
    unique_labels = np.unique(labels_subset)
    label_counts = Counter(labels_subset)
    top_labels = [label for label, _ in label_counts.most_common(30)]

    for label in unique_labels:
        mask = labels_subset == label
        if label in top_labels:
            ax.scatter(latent_2d[mask, 0], latent_2d[mask, 1],
                      label=f'Cat {label}', alpha=0.6, s=10)
        else:
            ax.scatter(latent_2d[mask, 0], latent_2d[mask, 1],
                      color='lightgray', alpha=0.3, s=5)

    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_xlabel('t-SNE Dimension 1', fontsize=12)
    ax.set_ylabel('t-SNE Dimension 2', fontsize=12)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close(fig)
    print(f"âœ“ t-SNE ì‹œê°í™” ì €ì¥: {save_path}")

# --- 9. ì¹´í…Œê³ ë¦¬ ìƒì„± (KMeans) + ì‹œê°í™” ---
# [Req 4, 5, 9]
def create_categories(model, dataloader, n_categories, device, output_dir=None):
    """
    í•™ìŠµëœ Autoencoderë¥¼ ì´ìš©í•´ Latent Vectorë¥¼ ì¶”ì¶œí•˜ê³  KMeans í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    + t-SNE ì‹œê°í™” ì¶”ê°€

    Args:
        output_dir: ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ (Noneì´ë©´ ì‹œê°í™” ìƒëµ)
    """
    model.to(device)
    model.eval()
    all_latents = []

    print("\nKMeans í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´ ì ì¬ ë²¡í„°(Latent Vector) ì¶”ì¶œ ì¤‘...")
    with torch.no_grad():
        for data in dataloader:
            data = data.to(device)
            _, latent = model(data) # (reconstructed, latent)
            all_latents.append(latent.cpu())

    all_latents_np = torch.cat(all_latents, dim=0).numpy()
    print(f"ì´ {all_latents_np.shape[0]}ê°œì˜ ì ì¬ ë²¡í„° ì¶”ì¶œ ì™„ë£Œ. (í˜•íƒœ: {all_latents_np.shape})")

    print(f"MiniBatchKMeans í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘ (N={n_categories})...")
    # MiniBatchKMeansëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ KMeansë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„
    kmeans = MiniBatchKMeans(n_clusters=n_categories,
                            random_state=42,
                            n_init=10,
                            batch_size=min(1024, len(all_latents_np)))
    kmeans.fit(all_latents_np)
    print("KMeans í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ.")

    # --- ë¶ˆëª…í™• ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ---
    # ê° ìƒ˜í”Œì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    labels = kmeans.labels_
    distances = np.min(kmeans.transform(all_latents_np), axis=1)

    # ê±°ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë¶ˆëª…í™• ì¹´í…Œê³ ë¦¬ íŒë‹¨ (ìƒìœ„ 10% ê±°ë¦¬ë¥¼ ë¶ˆëª…í™•ìœ¼ë¡œ ë¶„ë¥˜)
    distance_threshold = np.percentile(distances, 90)
    uncertain_mask = distances > distance_threshold

    # ë¶ˆëª…í™•í•œ ìƒ˜í”Œë“¤ì„ n_categories ë²ˆí˜¸ë¡œ ì¬í• ë‹¹
    labels_with_uncertain = labels.copy()
    labels_with_uncertain[uncertain_mask] = n_categories  # ë§ˆì§€ë§‰ ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸

    print(f"âœ“ ë¶ˆëª…í™• ì¹´í…Œê³ ë¦¬(Category {n_categories}): {uncertain_mask.sum()}ê°œ ìƒ˜í”Œ ({uncertain_mask.sum()/len(labels)*100:.2f}%)")

    # --- [Req 9] ì¹´í…Œê³ ë¦¬ í¸ì¤‘ë„(ë¶„í¬) ì¶œë ¥ ---
    labels = labels_with_uncertain  # ë¶ˆëª…í™• í¬í•¨ëœ ë ˆì´ë¸” ì‚¬ìš©
    label_counts = Counter(labels)
    sorted_counts = label_counts.most_common() # (label, count) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸

    print("\n" + "="*70)
    print("              ğŸ“Š Top 30 Most Frequent Categories ğŸ“Š")
    print("="*70)
    total_samples = len(labels)
    for i, (label, count) in enumerate(sorted_counts[:30]):
        percentage = (count / total_samples) * 100
        bar = 'â–ˆ' * int(percentage / 2)
        print(f"  {i+1:2d}. Category {label:04d}: {count:6d} ìƒ˜í”Œ ({percentage:5.2f}%) {bar}")
    print("="*70 + "\n")

    # t-SNE ì‹œê°í™” (output_dirì´ ì§€ì •ëœ ê²½ìš°)
    if output_dir:
        tsne_path = os.path.join(output_dir, 'latent_space_tsne.png')
        visualize_latent_space_tsne(all_latents_np, labels, tsne_path)

    return kmeans

# --- 7. ì¹´í…Œê³ ë¦¬ ì¶”ë¡  (ì‹ ê·œ í•¨ìˆ˜) ---
# [Req 5] ì €ì¥ëœ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬/KMeansë¡œ ìƒˆ ë°ì´í„°ì˜ íŒ¨í„´ ID ì¶”ë¡ 
def get_pattern_category(new_data_ticks, autoencoder, kmeans_model, feature_scalers, seq_len, device):
    """
    ìƒˆë¡œìš´ ë°ì´í„°(Aí‹±)ë¥¼ ë°›ì•„ ì–´ë–¤ íŒ¨í„´ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ”ì§€ ì¶”ë¡ í•©ë‹ˆë‹¤.

    Args:
        new_data_ticks (np.array): (seq_len, num_features) í˜•íƒœì˜ ì›ë³¸ ë°ì´í„°
        feature_scalers (dict): Featureë³„ ë…ë¦½ Scaler ë”•ì…”ë„ˆë¦¬
    """

    # ì…ë ¥ ë°ì´í„° ê²€ì¦
    if new_data_ticks.shape[0] != seq_len:
        raise ValueError(f"ì…ë ¥ ë°ì´í„° ê¸¸ì´ëŠ” {seq_len}ì´ì–´ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {new_data_ticks.shape[0]})")

    n_features = len(feature_scalers)
    if new_data_ticks.shape[1] != n_features:
        raise ValueError(f"ì…ë ¥ í”¼ì²˜ ê°œìˆ˜ëŠ” {n_features}ê°œì—¬ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {new_data_ticks.shape[1]})")

    # 1. Featureë³„ ë…ë¦½ ìŠ¤ì¼€ì¼ë§ ì ìš©
    scaled_data = np.zeros_like(new_data_ticks, dtype=np.float32)
    feature_names = list(feature_scalers.keys())

    for i, feature_name in enumerate(feature_names):
        scaler = feature_scalers[feature_name]
        scaled_data[:, i] = scaler.transform(new_data_ticks[:, i:i+1]).flatten()

    # 2. Convert to Tensor (Batch ì°¨ì› ì¶”ê°€)
    data_tensor = torch.tensor(scaled_data, dtype=torch.float32).unsqueeze(0).to(device)

    # 3. Get latent vector
    autoencoder.to(device)
    autoencoder.eval()
    with torch.no_grad():
        _, latent = autoencoder(data_tensor) # (reconstructed, latent)

    # 4. Predict category
    latent_np = latent.cpu().numpy()
    category = kmeans_model.predict(latent_np)[0]

    # 5. ë¶ˆëª…í™• ì¹´í…Œê³ ë¦¬ íŒë‹¨
    # ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    distances = kmeans_model.transform(latent_np)
    min_distance = np.min(distances)

    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ê°„ í‰ê·  ê±°ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„ê³„ê°’ ì„¤ì •
    n_clusters = kmeans_model.n_clusters
    cluster_centers = kmeans_model.cluster_centers_
    center_distances = np.linalg.norm(cluster_centers[:, np.newaxis] - cluster_centers, axis=2)
    avg_center_distance = np.mean(center_distances[center_distances > 0])
    distance_threshold = avg_center_distance * 0.5  # ì¤‘ì‹¬ ê°„ ê±°ë¦¬ì˜ 50%

    if min_distance > distance_threshold:
        category = n_clusters  # ë¶ˆëª…í™• ì¹´í…Œê³ ë¦¬ë¡œ ì¬í• ë‹¹

    return category  # ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ ë°˜í™˜

# --- 8. ë©”ì¸ ì‹¤í–‰ ---
if __name__ == '__main__':

    for ___ in range(100):
    
        # --- [Req 7] CUDA/CPU ì¥ì¹˜ ê²€ì¦ ---
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print("="*40)
        print("       ì¥ì¹˜ ê²€ì¦ (Device Verification)       ")
        print("="*40)
        print(f"PyTorch ë²„ì „: {torch.__version__}")
        print(f"CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"ì‚¬ìš© ì¤‘ì¸ GPU: {torch.cuda.get_device_name(0)}")
        else:
            print("!! ê²½ê³ : CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        print(f"ì„ íƒëœ ì¥ì¹˜: {device}")
        print("="*40)

        # --- 0. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ---
        BASE_DIR = './dumps'
        TICKER = 'BTC'
        INTERVAL = '3m'
        START_DATE = '2025-01-05'
        END_DATE = '2025-11-05'
        
        # [Req 1] ì‚¬ìš©í•  í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ (CSV ì»¬ëŸ¼ëª…ê³¼ ì¼ì¹˜í•´ì•¼ í•¨)
        # ì´ë™í‰ê·  ë° íŒŒìƒ ì§€í‘œ ì‚¬ìš©
        FEATURES = ['ma5', 'check_5_10', 'diff_s2e', 'diff_h2l', 'PON']
        INPUT_DIM = len(FEATURES) # 5
        
        # [Req 1, 3] ê³¼ê±° "A"í‹± (ìƒ˜í”Œ ê¸¸ì´). 30~300 ì‚¬ì´ë¡œ ì„¤ì •.
        SEQUENCE_LENGTH = 50
        MAX_SEQ_LEN = SEQUENCE_LENGTH # Positional Encodingì„ ìœ„í•´ ëª¨ë¸ì— ì „ë‹¬
        
        # ëª¨ë¸ íŒŒë¼ë¯¸í„° (ëŒ€í­ ê°œì„ ëœ ìš©ëŸ‰)
        D_MODEL = 256            # 128 -> 256 (í‘œí˜„ë ¥ ëŒ€í­ í–¥ìƒ)
        NHEAD = 8                # ì–´í…ì…˜ í—¤ë“œ ìœ ì§€
        NUM_ENCODER_LAYERS = 6   # 3 -> 6 (ê¹Šì´ 2ë°° ì¦ê°€)
        NUM_DECODER_LAYERS = 6   # 3 -> 6 (ê¹Šì´ 2ë°° ì¦ê°€)
        LATENT_DIM = 512         # 256 -> 512 (ì••ì¶•ë¥  ëŒ€í­ ê°œì„ , ë” ë§ì€ ì •ë³´ ë³´ì¡´)
        DROPOUT = 0.15           # 0.2 -> 0.15 (ëª¨ë¸ ìš©ëŸ‰ ì¦ê°€ë¡œ ì•½ê°„ ì™„í™”)

        # [Req 4] ì¹´í…Œê³ ë¦¬ ìˆ˜
        N_CATEGORIES = 500

        # í•™ìŠµ íŒŒë¼ë¯¸í„° (ê°œì„ ë¨)
        BATCH_SIZE = 512      # 4096 -> 2048 (ëª¨ë¸ ìš©ëŸ‰ ì¦ê°€ë¡œ ë°°ì¹˜ í¬ê¸° ê°ì†Œ)
        EPOCHS = 2000            # [Req 6] ì¡°ê¸° ì¢…ë£Œë˜ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ ì„¤ì •
        VALIDATION_SPLIT_RATIO = 0.1 # 10%ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©

        # [Req 6] ì¡°ê¸° ì¢…ë£Œ Patience
        # ëª¨ë¸ ìš©ëŸ‰ ì¦ê°€ë¡œ í•™ìŠµ ì‹œê°„ì´ ê¸¸ì–´ì§€ë¯€ë¡œ Patience ì¦ê°€
        EARLY_STOPPING_PATIENCE = 150  # 100 -> 150 (ì¶©ë¶„í•œ í•™ìŠµ ê¸°íšŒ ì œê³µ)
        LEARNING_RATE = 1e-4           # 2e-4 -> 1e-4 (ë” ì•ˆì •ì ì¸ í•™ìŠµ)

        # Contrastive Loss íŒŒë¼ë¯¸í„°
        CONTRASTIVE_WEIGHT = 0.0       # Contrastive Loss ë¹„í™œì„±í™” (ëª¨ë¸ ì•ˆì •ì„± í–¥ìƒ)
        WARMUP_EPOCHS = 10             # 5 -> 10 (ëª¨ë¸ ìš©ëŸ‰ ì¦ê°€ë¡œ Warmup ê¸°ê°„ ì—°ì¥)
        
        # [Req 10] Train Type (ê²½ë¡œëª…ì— ì‚¬ìš©)
        TRAIN_TYPE = 'price' # 'volume' -> 'price'ë¡œ ë³€ê²½
        
        # ì €ì¥ íŒŒì¼ëª…
        MODELS_DIR = './models'
        if not os.path.exists(MODELS_DIR): os.makedirs(MODELS_DIR)
        ticker_dir = os.path.join(MODELS_DIR, TICKER)
        if not os.path.exists(ticker_dir): os.makedirs(ticker_dir)
        interval_dir = os.path.join(ticker_dir, INTERVAL)
        if not os.path.exists(interval_dir): os.makedirs(interval_dir)
        train_type_dir = os.path.join(interval_dir, TRAIN_TYPE)
        if not os.path.exists(train_type_dir): os.makedirs(train_type_dir)
        sequence_length_dir = os.path.join(train_type_dir, str(SEQUENCE_LENGTH))
        if not os.path.exists(sequence_length_dir): os.makedirs(sequence_length_dir)
        #N_CATEGORIES
        n_categories_dir = os.path.join(sequence_length_dir, str(N_CATEGORIES))
        if not os.path.exists(n_categories_dir): os.makedirs(n_categories_dir)

        
        # [Req 2, 5, 8] ì €ì¥ ê²½ë¡œ
        SCALER_PATH = os.path.join(n_categories_dir, f'{TRAIN_TYPE}_scaler.joblib')
        MODEL_PATH = os.path.join(n_categories_dir, 'transformer_autoencoder.pth') # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        KMEANS_PATH = os.path.join(n_categories_dir, 'pattern_categories.joblib')

        # --- 1. ë°ì´í„° ë¡œë“œ ---
        full_df = load_data_from_dumps(BASE_DIR, TICKER, INTERVAL, START_DATE, END_DATE, FEATURES)
        
        if full_df.empty:
            print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            # (í•„ìš”ì‹œ ê°€ìƒ ë°ì´í„° ìƒì„±)
            # print("ê°€ìƒ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (10000 í‹±).")
            # data_dict = {f: np.random.rand(10000) for f in FEATURES}
            # full_df = pd.DataFrame(data_dict)
        else:
            print(f"ì´ {len(full_df)}ê°œì˜ í‹±(row)ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        # --- 2. ì „ì²˜ë¦¬ (ìŠ¤ì¼€ì¼ë§) [Req 2] ---
        # ScalerëŠ” ì „ì²´ ë°ì´í„°ê°€ ì•„ë‹Œ **í•™ìŠµ ë°ì´í„°(train_data) ê¸°ì¤€**ìœ¼ë¡œ fití•´ì•¼
        # Data Leakage(ë°ì´í„° ìœ ì¶œ)ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ì‹œê³„ì—´ì´ë¯€ë¡œ shuffle=Falseë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
        
        # (1) Train/Validation ë°ì´í„° ë¶„ë¦¬ (DataFrame ê¸°ì¤€)
        train_df, val_df = train_test_split(full_df, 
                                            test_size=VALIDATION_SPLIT_RATIO, 
                                            shuffle=False) # ì‹œê³„ì—´ì´ë¯€ë¡œ ìˆœì„œ ìœ ì§€
        
        # (2) Featureë³„ ë…ë¦½ ìŠ¤ì¼€ì¼ë§ (ê° í”¼ì²˜ì˜ ìŠ¤ì¼€ì¼ ì°¨ì´ í•´ì†Œ)
        # FEATURES = ['ma5', 'check_5_10', 'diff_s2e', 'diff_h2l', 'PON']

        def scale_features_independently(df, scalers=None, fit=False):
            """ê° featureë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§"""
            scaled_data = np.zeros_like(df.values, dtype=np.float32)

            if scalers is None:
                scalers = {}

            for i, feature_name in enumerate(FEATURES):
                if fit:
                    # ìƒˆë¡œìš´ Scaler ìƒì„± ë° fit
                    scaler = StandardScaler()
                    scaler.fit(df.iloc[:, i:i+1])  # ë‹¨ì¼ ì»¬ëŸ¼
                    scalers[feature_name] = scaler

                # Transform
                scaled_data[:, i] = scalers[feature_name].transform(df.iloc[:, i:i+1]).flatten()

            return scaled_data, scalers

        # (3) Scaler ë¡œë“œ ë˜ëŠ” ìƒì„±
        if os.path.exists(SCALER_PATH):
            print(f"\n'{SCALER_PATH}'ì—ì„œ ê¸°ì¡´ Scalerë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
            feature_scalers = joblib.load(SCALER_PATH)

            # Train/Val/Full ë°ì´í„° ìŠ¤ì¼€ì¼ë§
            scaled_data_train, _ = scale_features_independently(train_df[FEATURES], feature_scalers, fit=False)
            scaled_data_val, _ = scale_features_independently(val_df[FEATURES], feature_scalers, fit=False)
            scaled_data_full, _ = scale_features_independently(full_df[FEATURES], feature_scalers, fit=False)
        else:
            print(f"\n'{SCALER_PATH}'ì— Scalerê°€ ì—†ìŠµë‹ˆë‹¤. Train ë°ì´í„°ë¡œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

            # Train ë°ì´í„°ë¡œ fití•˜ê³  ë³€í™˜
            scaled_data_train, feature_scalers = scale_features_independently(train_df[FEATURES], fit=True)

            # Val/Full ë°ì´í„°ëŠ” ê°™ì€ scalerë¡œ ë³€í™˜ë§Œ
            scaled_data_val, _ = scale_features_independently(val_df[FEATURES], feature_scalers, fit=False)
            scaled_data_full, _ = scale_features_independently(full_df[FEATURES], feature_scalers, fit=False)

            # Scaler ì €ì¥
            joblib.dump(feature_scalers, SCALER_PATH)
            print(f"Featureë³„ Scaler ì €ì¥ ì™„ë£Œ: {SCALER_PATH}")

        print(f"ë°ì´í„° ë¶„í• : Train {len(scaled_data_train)}ê°œ, Validation {len(scaled_data_val)}ê°œ")

        # --- 3. Dataset ë° DataLoader (Train/Validation ë¶„ë¦¬) ---
        # [Req 6]
        # Training: ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ë‹¤ì–‘í•œ íŒ¨í„´ í•™ìŠµ
        train_dataset = PricePatternDataset(scaled_data_train, SEQUENCE_LENGTH, random_sampling=True)
        # Validation: ê³ ì • ìƒ˜í”Œë§ìœ¼ë¡œ ì¼ê´€ëœ í‰ê°€ (ê³¼ì í•© ê°ì§€ ì •í™•ë„ í–¥ìƒ)
        val_dataset = PricePatternDataset(scaled_data_val, SEQUENCE_LENGTH, random_sampling=False)

        # í•™ìŠµ ë°ì´í„°ëŠ” ì„ì–´ì„œ(shuffle=True) ëª¨ë¸ì´ ìˆœì„œì— ê³¼ì í•©ë˜ëŠ” ê²ƒì„ ë°©ì§€
        train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
        # ê²€ì¦ ë°ì´í„°ëŠ” ìˆœì„œëŒ€ë¡œ(shuffle=False) í‰ê°€
        val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

        # (ë°ì´í„° í˜•íƒœ í™•ì¸)
        try:
            sample_data = next(iter(train_dataloader))
            print(f"ë°ì´í„°ì…‹ ìƒ˜í”Œ í˜•íƒœ (Batch, Seq_Len, Features): {sample_data.shape}")
        except ValueError as e:
            print(f"ë°ì´í„°ì…‹ ìƒì„± ì˜¤ë¥˜: {e}")
            print("ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ 1ê°œì˜ ë°°ì¹˜ë„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. START_DATEë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            exit()


        # --- 4. Autoencoder ëª¨ë¸ ì´ˆê¸°í™” ---
        autoencoder_model = TransformerAutoencoder(
            input_dim=INPUT_DIM,
            d_model=D_MODEL,
            nhead=NHEAD,
            num_encoder_layers=NUM_ENCODER_LAYERS,
            num_decoder_layers=NUM_DECODER_LAYERS,
            latent_dim=LATENT_DIM,
            max_seq_len=MAX_SEQ_LEN,
            dropout=DROPOUT
        )

        # --- [Req 7, 8] ëª¨ë¸ ë¡œë“œ (í•™ìŠµ ì¬ê°œ) ---
        # EarlyStoppingì´ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ MODEL_PATHì— ì €ì¥í•˜ë¯€ë¡œ,
        # ì´ ê²½ë¡œëŠ” 'ìµœê·¼' ëª¨ë¸ì´ ì•„ë‹Œ 'ìµœì ' ëª¨ë¸ì…ë‹ˆë‹¤.
        if os.path.exists(MODEL_PATH):
            print(f"\n'{MODEL_PATH}' ì—ì„œ ê¸°ì¡´ ë² ìŠ¤íŠ¸ ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            try:
                autoencoder_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
                print("ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ. ì´ì–´ì„œ í•™ìŠµí•©ë‹ˆë‹¤.\n")
            except Exception as e:
                print(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n")
        else:
            print(f"\n'{MODEL_PATH}' ì—ì„œ ê¸°ì¡´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n")

        # --- 5. Autoencoder ëª¨ë¸ í•™ìŠµ (ì¡°ê¸° ì¢…ë£Œ ì ìš©) ---
        # [Req 6]
        autoencoder_model = train_autoencoder(
            model=autoencoder_model,
            train_loader=train_dataloader,
            val_loader=val_dataloader,
            model_path=MODEL_PATH,  # ë² ìŠ¤íŠ¸ ëª¨ë¸ì´ ì—¬ê¸°ì— ì €ì¥ë¨
            epochs=EPOCHS,
            lr=LEARNING_RATE,
            patience=EARLY_STOPPING_PATIENCE,
            device=device,
            contrastive_weight=CONTRASTIVE_WEIGHT,
            warmup_epochs=WARMUP_EPOCHS
        )

        # --- 5.5. ì¬êµ¬ì¶• í’ˆì§ˆ ì‹œê°í™” ---
        recon_viz_path = os.path.join(n_categories_dir, 'reconstruction_quality.png')
        visualize_reconstruction_quality(
            model=autoencoder_model,
            dataloader=val_dataloader,
            device=device,
            save_path=recon_viz_path,
            num_samples=5
        )
        
        # --- 6. "ì¹´í…Œê³ ë¦¬" ìƒì„± (KMeans) + t-SNE ì‹œê°í™” ---
        # [Req 4, 5, 9]
        # train_autoencoder í•¨ìˆ˜ê°€ ìµœì  ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜í–ˆìœ¼ë¯€ë¡œ
        # autoencoder_modelì€ í˜„ì¬ 'ë² ìŠ¤íŠ¸ ëª¨ë¸' ìƒíƒœì…ë‹ˆë‹¤.

        # K-MeansëŠ” ì „ì²´ ë°ì´í„°(Train+Val)ë¡œ ìƒì„±
        # K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´ ê³ ì • ìƒ˜í”Œë§ ì‚¬ìš© (ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´)
        full_dataset = PricePatternDataset(scaled_data_full, SEQUENCE_LENGTH, random_sampling=False)
        # K-Means í•™ìŠµ ì‹œì—ëŠ” ë°ì´í„°ë¥¼ ì„ì„ í•„ìš” ì—†ìŒ
        full_dataloader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False)

        kmeans_model = create_categories(
            model=autoencoder_model,
            dataloader=full_dataloader,
            n_categories=N_CATEGORIES,
            device=device,
            output_dir=n_categories_dir  # t-SNE ì‹œê°í™” ì €ì¥
        )
        
        # [Req 5] KMeans ëª¨ë¸ ì €ì¥
        joblib.dump(kmeans_model, KMEANS_PATH)
        print(f"KMeans (ì¹´í…Œê³ ë¦¬) ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {KMEANS_PATH}")

        
        # --- 7. "ì¹´í…Œê³ ë¦¬" ì¬ì‚¬ìš© ì˜ˆì‹œ ---
        print("\n" + "="*40)
        print("      ğŸ”„ ì¹´í…Œê³ ë¦¬ ì¬ì‚¬ìš©(ì¶”ë¡ ) í…ŒìŠ¤íŠ¸ ğŸ”„")
        print("="*40)
        
        # (ê°€ìƒì˜ ìƒˆ ë°ì´í„°, 5í”¼ì²˜: ma5, check_5_10, diff_s2e, diff_h2l, PON)
        # [Req 1] (SEQUENCE_LENGTH, INPUT_DIM) í˜•íƒœì˜ NumPy ë°°ì—´
        new_ticks_A = np.random.rand(SEQUENCE_LENGTH, INPUT_DIM) * 100 + 150000000
        
        # ì €ì¥ëœ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        print("ì €ì¥ëœ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬/KMeans ë¡œë“œ ì¤‘...")
        loaded_autoencoder = TransformerAutoencoder(
            input_dim=INPUT_DIM, d_model=D_MODEL, nhead=NHEAD,
            num_encoder_layers=NUM_ENCODER_LAYERS,
            num_decoder_layers=NUM_DECODER_LAYERS,
            latent_dim=LATENT_DIM, max_seq_len=MAX_SEQ_LEN,
            dropout=DROPOUT
        )
        loaded_autoencoder.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        
        loaded_scaler = joblib.load(SCALER_PATH)
        loaded_kmeans = joblib.load(KMEANS_PATH)

        print("ì¶”ë¡  ì‹œì‘...")
        category = get_pattern_category(
            new_data_ticks=new_ticks_A,
            autoencoder=loaded_autoencoder,
            kmeans_model=loaded_kmeans,
            feature_scalers=loaded_scaler,  # ì´ì œ dict í˜•íƒœ
            seq_len=SEQUENCE_LENGTH,
            device=device
        )
        
        print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ìƒˆë¡œìš´ {SEQUENCE_LENGTH}í‹± ë°ì´í„°ì˜ íŒ¨í„´ ì¹´í…Œê³ ë¦¬: {category}")
        print("="*40)
        
        # --- ë©”ëª¨ë¦¬ ì •ë¦¬ (ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•œ ì´ˆê¸°í™”) ---
        print("\n[ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...]")
        
        # 1. ëª¨ë¸ë“¤ì„ CPUë¡œ ì´ë™ í›„ ì‚­ì œ
        if 'autoencoder_model' in locals():
            autoencoder_model.cpu()
            del autoencoder_model
        
        if 'loaded_autoencoder' in locals():
            loaded_autoencoder.cpu()
            del loaded_autoencoder
        
        # 2. ë°ì´í„°ë¡œë”ì™€ ë°ì´í„°ì…‹ ì‚­ì œ
        if 'train_dataloader' in locals():
            del train_dataloader
        if 'val_dataloader' in locals():
            del val_dataloader
        if 'full_dataloader' in locals():
            del full_dataloader
        if 'train_dataset' in locals():
            del train_dataset
        if 'val_dataset' in locals():
            del val_dataset
        if 'full_dataset' in locals():
            del full_dataset
        
        # 3. ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ë°°ì—´ ì‚­ì œ
        if 'scaled_data_full' in locals():
            del scaled_data_full
        if 'scaled_data_train' in locals():
            del scaled_data_train
        if 'scaled_data_val' in locals():
            del scaled_data_val
        
        # 4. DataFrame ì‚­ì œ
        if 'full_df' in locals():
            del full_df
        if 'train_df' in locals():
            del train_df
        if 'val_df' in locals():
            del val_df
        
        # 5. ê¸°íƒ€ ë³€ìˆ˜ ì‚­ì œ
        if 'feature_scalers' in locals():
            del feature_scalers
        if 'loaded_scaler' in locals():
            del loaded_scaler
        if 'kmeans_model' in locals():
            del kmeans_model
        if 'loaded_kmeans' in locals():
            del loaded_kmeans
        if 'new_ticks_A' in locals():
            del new_ticks_A
        if 'sample_data' in locals():
            del sample_data
        
        # 6. CUDA ìºì‹œ ì •ë¦¬ (GPU ë©”ëª¨ë¦¬ í•´ì œ)
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            print(f"  âœ“ GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
        
        # 7. Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        gc.collect()
        print(f"  âœ“ Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì™„ë£Œ")
        
        print("[ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ]\n")